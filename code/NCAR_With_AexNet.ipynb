{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6187fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf \n",
    "# import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d84e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"C:\\\\Users\\\\gazur\\\\Desktop\\\\Computer Vision\\\\Imbalance medical image synthesis with label noise\\\\DATASET\\\\Finale_Data/x_upsampled.npy\") \n",
    "y_train = np.load(\"C:\\\\Users\\\\gazur\\\\Desktop\\\\Computer Vision\\\\Imbalance medical image synthesis with label noise\\\\DATASET\\\\Finale_Data/Features/NCAR/_20.npy\")\n",
    "x_test = np.load(\"C:\\\\Users\\\\gazur\\\\Desktop\\\\Computer Vision\\\\Imbalance medical image synthesis with label noise\\\\DATASET\\\\Finale_Data/x_test.npy\")\n",
    "y_test = np.load(\"C:\\\\Users\\\\gazur\\\\Desktop\\\\Computer Vision\\\\Imbalance medical image synthesis with label noise\\\\DATASET\\\\Finale_Data/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e95190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1627, 256, 256, 3), (1627, 2), (379, 256, 256, 3), (379, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71df2aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Learning Rate Annealer\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23d7ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\envs\\GPU_Keras\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\envs\\GPU_Keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              67112960  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 2002      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 91,782,754\n",
      "Trainable params: 91,761,614\n",
      "Non-trainable params: 21,140\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Importing library\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1000)\n",
    "\n",
    "#Instantiation\n",
    "AlexNet = Sequential()\n",
    "\n",
    "#1st Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=96, input_shape=(256,256,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#5th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "AlexNet.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "AlexNet.add(Dense(4096, input_shape=(256,256,3,)))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "AlexNet.add(Dense(1000))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#Output Layer\n",
    "AlexNet.add(Dense(2))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('softmax'))\n",
    "\n",
    "#Model Summary\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac074f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "534fb771",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adagrad(learning_rate=0.001),metrics=['accuracy'])\n",
    "\n",
    "# start_time = time.time()\n",
    "# AlexNet.fit(x_train, y_train, batch_size=16, epochs=1, callbacks = [lrr], verbose=1)\n",
    "# score = AlexNet.evaluate(x_test, y_test, batch_size=32)\n",
    "# end_time = time.time()\n",
    "# print(\"--- Time taken to train : %s minuts ---\" % ((end_time - start_time)//60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f765403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\envs\\GPU_Keras\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Anaconda\\envs\\GPU_Keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1627 samples, validate on 379 samples\n",
      "Epoch 1/10\n",
      "1627/1627 [==============================] - 153s 94ms/step - loss: 0.7118 - accuracy: 0.5900 - val_loss: 3.0350 - val_accuracy: 0.8021\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\GPU_Keras\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1627/1627 [==============================] - 139s 86ms/step - loss: 0.6306 - accuracy: 0.6724 - val_loss: 3.0350 - val_accuracy: 0.8021\n",
      "Epoch 3/10\n",
      "1627/1627 [==============================] - 142s 87ms/step - loss: 0.6018 - accuracy: 0.6921 - val_loss: 3.0350 - val_accuracy: 0.8021\n",
      "Epoch 4/10\n",
      "1627/1627 [==============================] - 142s 87ms/step - loss: 0.5579 - accuracy: 0.7265 - val_loss: 3.0350 - val_accuracy: 0.8021\n",
      "Epoch 5/10\n",
      "1627/1627 [==============================] - 141s 87ms/step - loss: 0.5142 - accuracy: 0.7554 - val_loss: 3.0350 - val_accuracy: 0.8021\n",
      "Epoch 6/10\n",
      "1627/1627 [==============================] - 144s 89ms/step - loss: 0.4498 - accuracy: 0.8021 - val_loss: 3.0350 - val_accuracy: 0.8021\n",
      "Epoch 7/10\n",
      "1627/1627 [==============================] - 151s 93ms/step - loss: 0.3807 - accuracy: 0.8519 - val_loss: 3.0350 - val_accuracy: 0.8021\n",
      "Epoch 8/10\n",
      "1627/1627 [==============================] - 149s 92ms/step - loss: 0.3166 - accuracy: 0.8888 - val_loss: 3.0350 - val_accuracy: 0.8021\n",
      "Epoch 9/10\n",
      "1627/1627 [==============================] - 146s 90ms/step - loss: 0.2664 - accuracy: 0.9262 - val_loss: 3.0350 - val_accuracy: 0.8021\n",
      "Epoch 10/10\n",
      "1627/1627 [==============================] - 148s 91ms/step - loss: 0.2389 - accuracy: 0.9588 - val_loss: 3.0350 - val_accuracy: 0.8021\n",
      "--- Time taken to train : 24.0 minuts ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "AlexNet.fit(x_train, y_train,\n",
    "            batch_size=16,\n",
    "            epochs=10,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=[lrr], # early_stopping, checkpointer, reduce_lr\n",
    "            shuffle=False)\n",
    "end_time = time.time()\n",
    "print(\"--- Time taken to train : %s minuts ---\" % ((end_time - start_time)//60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d498654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
