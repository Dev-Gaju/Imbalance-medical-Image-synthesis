{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-dtOzHyQbFTR"
   },
   "source": [
    "### Trains a model on the ISIC-2016 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FBbPnWmK5z5W"
   },
   "outputs": [],
   "source": [
    "# install libs\n",
    "!pip install image-classifiers==0.2.2\n",
    "!pip install image-classifiers==1.0.0b1\n",
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2115,
     "status": "ok",
     "timestamp": 1576624808585,
     "user": {
      "displayName": "Md Hasib Zunair 1320262643",
      "photoUrl": "",
      "userId": "12069756592370329757"
     },
     "user_tz": 300
    },
    "id": "UCMd_LsAKLxC",
    "outputId": "d3133623-339c-4766-c751-d8ed7c3584f0"
   },
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1576624653863,
     "user": {
      "displayName": "Md Hasib Zunair 1320262643",
      "photoUrl": "",
      "userId": "12069756592370329757"
     },
     "user_tz": 300
    },
    "id": "PFJE3qVgJYN9",
    "outputId": "a0cebd0f-65d5-478d-e285-93c085aa1beb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Print version\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"Tensorflow Version\", tf.__version__)\n",
    "\n",
    "\n",
    "# GPU test\n",
    "#from tensorflow.python.client import device_lib\n",
    "#def get_available_gpus():\n",
    "#    local_device_protos = device_lib.list_local_devices()\n",
    "#    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "#print(get_available_gpus())\n",
    "\n",
    "# Get compute specs\n",
    "#from tensorflow.python.client import device_lib\n",
    "#device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T3jL0aXh53ml"
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import os \n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from keras.utils import np_utils\n",
    "from imgaug import augmenters as iaa    \n",
    "import itertools\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Print version\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"Tensorflow Version\", tf.__version__)\n",
    "\n",
    "\n",
    "# GPU test\n",
    "from tensorflow.python.client import device_lib\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())\n",
    "\n",
    "# Get compute specs\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "\n",
    "\n",
    "# Helpers functions\n",
    "\n",
    "def create_directory(directory):\n",
    "    '''\n",
    "    Creates a new folder in the specified directory if the folder doesn't exist.\n",
    "    INPUT\n",
    "        directory: Folder to be created, called as \"folder/\".\n",
    "    OUTPUT\n",
    "        New folder in the current directory.\n",
    "    '''\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def plot_hist(img):\n",
    "    \n",
    "    img_flat = img.flatten()\n",
    "    print(min(img_flat), max(img_flat))\n",
    "    \n",
    "    plt.hist(img_flat, bins=20, color='c')\n",
    "    #plt.title(\"Data distribution\")\n",
    "    plt.xlabel(\"Pixel values\")\n",
    "    plt.grid(True)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Focal loss function\n",
    "##################################################################################\n",
    "# Paper: https://arxiv.org/abs/1708.02002\n",
    "\n",
    "#Focal loss down-weights the well-classified examples. This has\n",
    "#the net effect of putting more training emphasis on that data that is hard to classify. \n",
    "#In a practical setting where we have a data imbalance, our majority class will quickly \n",
    "#become well-classified since we have much more data for it. Thus, in order to insure that we\n",
    "#also achieve high accuracy on our minority class, we can use the focal loss to give those minority\n",
    "#class examples more relative weight during training. \n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "\tdef focal_loss_fixed(y_true, y_pred):\n",
    "\t\tpt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "\t\tpt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\t\treturn -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "\treturn focal_loss_fixed\n",
    "##################################################################################\n",
    "\n",
    "\n",
    "# Define paths\n",
    "base_path = os.path.abspath(\"../\")\n",
    "dataset_path = os.path.join(base_path, \"dataset\", \"isic2016numpy\")\n",
    "model_path = os.path.join(base_path, \"models\")\n",
    "print(os.listdir(dataset_path))\n",
    "\n",
    "\n",
    "# Load data\n",
    "x_train = np.load(\"{}/x_upsampled.npy\".format(dataset_path)) \n",
    "y_train = np.load(\"{}/y_uspampled.npy\".format(dataset_path))\n",
    "x_test = np.load(\"{}/x_test.npy\".format(dataset_path))\n",
    "y_test = np.load(\"{}/y_test.npy\".format(dataset_path))\n",
    "\n",
    "\n",
    "# Shuffle training dataset\n",
    "flag = 1\n",
    "if flag == 1:\n",
    "    # Shuffle data\n",
    "    print(\"Shuffling data\")\n",
    "    s = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    x_train = x_train[s]\n",
    "    y_train = y_train[s]\n",
    "else:\n",
    "    print(\"Not shuffling...\")\n",
    "    pass\n",
    "\n",
    "\n",
    "# Flag for increasing training set\n",
    "augment_data = False\n",
    "augment_factor = 5 # 5x, 10x\n",
    "\n",
    "if augment_data is True:\n",
    "    print(\"Increasing training set via data augmentation...\")\n",
    "\n",
    "  # 1\n",
    "  seq_1 = iaa.Sequential([\n",
    "      iaa.ContrastNormalization((0.5, 1.5)),\n",
    "      \n",
    "      iaa.Crop(percent=(0, 0.2)), # random crops\n",
    "      # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "      # But we only blur about 50% of all images.\n",
    "      iaa.Sometimes(0.5,\n",
    "          iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "      ),\n",
    "      iaa.Sometimes(0.7, \n",
    "          iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n",
    "      ),\n",
    "      # Make some images brighter and some darker.\n",
    "      # In 20% of all cases, we sample the multiplier once per channel,\n",
    "      # which can end up changing the color of the images.\n",
    "      #iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "      \n",
    "      iaa.Affine(\n",
    "          rotate=(-25, 25),\n",
    "      ),\n",
    "      iaa.Affine(\n",
    "          translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "      ),\n",
    "      iaa.Affine(\n",
    "          shear=(-25, 25)\n",
    "      ),\n",
    "      \n",
    "      iaa.Sometimes(0.8, \n",
    "          iaa.CoarseDropout(0.03, size_percent=0.1)\n",
    "      ),\n",
    "      iaa.Sequential([\n",
    "          iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n",
    "          iaa.WithChannels(0, iaa.Add((50, 100))),\n",
    "          iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\")\n",
    "      ]),\n",
    "      \n",
    "  ], random_order=True) # apply augmenters in random order\n",
    "\n",
    "\n",
    "\n",
    "  # 2\n",
    "  seq_2 = iaa.Sequential([\n",
    "      iaa.ContrastNormalization((0.5, 1.5)),\n",
    "      iaa.Sometimes(0.5,\n",
    "          iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "      ),\n",
    "      iaa.Sometimes(0.7, \n",
    "          iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n",
    "      ),\n",
    "      iaa.Affine(\n",
    "          rotate=(-25, 25),\n",
    "      ),\n",
    "      iaa.Affine(\n",
    "          translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "      ),\n",
    "      iaa.Affine(\n",
    "          shear=(-25, 25)\n",
    "      ),\n",
    "  ], random_order=True) # apply augmenters in random order\n",
    "\n",
    "\n",
    "\n",
    "  def augment_data_minimal( x_values, y_values ):\n",
    "      counter = 0\n",
    "      RESIZE_DIM = 256\n",
    "      X_values_augmented = []\n",
    "      Y_values_augmented = []\n",
    "      for x in x_values:\n",
    "          for p in range(augment_factor):\n",
    "              \n",
    "              # seq 1\n",
    "              Y_values_augmented.append( y_values[counter] )\n",
    "              images_aug = seq_1.augment_images(x.reshape(1,RESIZE_DIM,RESIZE_DIM,3))   \n",
    "              X_values_augmented.append( images_aug.reshape(RESIZE_DIM,RESIZE_DIM,3))\n",
    "\n",
    "              # seq 2\n",
    "              #Y_values_augmented.append( y_values[counter] )\n",
    "              #images_aug = seq_2.augment_images(x.reshape(1,RESIZE_DIM,RESIZE_DIM,3))   \n",
    "              #X_values_augmented.append( images_aug.reshape(RESIZE_DIM,RESIZE_DIM,3))\n",
    "\n",
    "          counter = counter + 1\n",
    "      \n",
    "      # Quick math!\n",
    "      # prev number of images = n\n",
    "      # augmented number of images = n * 5 ( 2 seq 2 times)\n",
    "      \n",
    "      X_values_augmented = np.asarray( X_values_augmented )\n",
    "      Y_values_augmented = np.asarray( Y_values_augmented )\n",
    "      return (X_values_augmented, Y_values_augmented)\n",
    "\n",
    "  (x_aug, y_aug) = augment_data_minimal( x_train, y_train)\n",
    "  print(\"Augmented sample size: \", x_aug.shape, y_aug.shape)\n",
    "\n",
    "  x_train = np.concatenate( (x_train, x_aug), axis = 0)\n",
    "  y_train = np.concatenate( (y_train, y_aug), axis = 0)\n",
    "\n",
    "else:\n",
    "  print(\"Not increasing dataset via augmentation..\")\n",
    "  pass\n",
    "\n",
    "\n",
    "# Show shape\n",
    "print(\"Dataset sample size :\", x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "# Sanity check on training data\n",
    "#img = x_train[0]\n",
    "#plot_hist(img)\n",
    "\n",
    "#plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mkxe1Mp26ZQi"
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import keras\n",
    "from classification_models.keras import Classifiers\n",
    "\n",
    "# Define architecture\n",
    "arch, preprocess_input = Classifiers.get('vgg16') \n",
    "\n",
    "\n",
    "# Preprocess the dataset\n",
    "\n",
    "# 1. Use model preprocessing\n",
    "#x_train = preprocess_input(x_train)\n",
    "#x_test = preprocess_input(x_test)\n",
    "\n",
    "\n",
    "# 2. Use standard preprocessing\n",
    "prepro = False # False when using synthetic data\n",
    "\n",
    "if prepro == True:\n",
    "  print(\"Preprocessing training data\")\n",
    "  x_train = x_train.astype('float32')\n",
    "  x_train /= 255\n",
    "else:\n",
    "  print(\"Not preprocessing training data, already preprocessed in MeGAN generator.\")\n",
    "  pass\n",
    "\n",
    "# Standardize test set\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Sanity check on preprocessed data\n",
    "#img = x_test[0]\n",
    "#plot_hist(img)\n",
    "#plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "teeONwaw6ZYa"
   },
   "outputs": [],
   "source": [
    "# Experiment name\n",
    "EXP_NAME = \"b2m_510_2nd\"\n",
    "\n",
    "# Create folder for the experiment\n",
    "create_directory(\"{}/{}\".format(base_path, EXP_NAME))\n",
    "output_path = os.path.join(base_path, EXP_NAME)\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "weights_path = \"{}/{}.h5\".format(output_path, EXP_NAME)\n",
    "checkpointer = ModelCheckpoint(filepath=weights_path, verbose=1, monitor='val_loss', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-8, mode='auto') # new_lr = lr * factor\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, verbose=1, patience=8, mode='auto', restore_best_weights=True)\n",
    "csv_logger = CSVLogger('{}/{}_training.csv'.format(output_path, EXP_NAME))\n",
    "\n",
    "\n",
    "# Define class weights for imbalacned data\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(np.argmax(y_train, axis=1)), np.argmax(y_train, axis=1))\n",
    "print(class_weights)\n",
    "\n",
    "\n",
    "def my_awesome_model():\n",
    "  \n",
    "  '''Awesomest model'''\n",
    "\n",
    "  # Get backbone network\n",
    "  base_model = arch(input_shape=(256,256,3), weights='imagenet', include_top=False)\n",
    "  \n",
    "  # Add GAP layer\n",
    "  x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "  # Add FC layer\n",
    "  output = keras.layers.Dense(2, activation='softmax', trainable=True)(x) \n",
    "\n",
    "  # Freeze layers\n",
    "  #for layer in base_model.layers[:]:\n",
    "    #layer.trainable=False\n",
    "  \n",
    "  # Build model\n",
    "  model = keras.models.Model(inputs=[base_model.input], outputs=[output])\n",
    "\n",
    "  # Optimizers\n",
    "  adadelta = optimizers.Adadelta(lr=0.001) \n",
    "  \n",
    "  # Compile\n",
    "  model.compile(optimizer=adadelta, loss= [focal_loss(alpha=.25, gamma=2)], metrics=['accuracy']) \n",
    "  \n",
    "  # Output model configuration\n",
    "  model.summary()\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "model = None\n",
    "model = my_awesome_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F43HGExG6ZbU"
   },
   "outputs": [],
   "source": [
    "# Train the awesome model\n",
    "\n",
    "# Configuration\n",
    "batch_size = 16\n",
    "epochs = 300 \n",
    "\n",
    "# Flag for on-the-fly data augmentation\n",
    "data_augmentation = False\n",
    "\n",
    "# Calculate the starting time    \n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def train_model(epochs):\n",
    "  if not data_augmentation:\n",
    "      print('Not using data augmentation.')\n",
    "      model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=(x_test, y_test),\n",
    "                class_weight = class_weights,\n",
    "                callbacks=[csv_logger, early_stopping, reduce_lr, checkpointer], # early_stopping, checkpointer, reduce_lr\n",
    "                shuffle=False)\n",
    "  else:\n",
    "      print('Using real-time data augmentation.')\n",
    "      # This will do preprocessing and realtime data augmentation:\n",
    "      datagen = ImageDataGenerator(\n",
    "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "          samplewise_center=False,  # set each sample mean to 0\n",
    "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "          samplewise_std_normalization=False,  # divide each input by its std\n",
    "          zca_whitening=False,  # apply ZCA whitening\n",
    "          zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "          rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "          width_shift_range=0.25, # randomly shift images horizontally (fraction of total width)\n",
    "          height_shift_range=0.25, # randomly shift images vertically (fraction of total height)\n",
    "          shear_range=0.2,  # set range for random shear\n",
    "          zoom_range=0.2,  # set range for random zoom\n",
    "          channel_shift_range=0.,  # set range for random channel shifts\n",
    "          fill_mode='nearest', # set mode for filling points outside the input boundaries\n",
    "          cval=0.,  # value used for fill_mode = \"constant\"\n",
    "          horizontal_flip=True,  # randomly flip images\n",
    "          vertical_flip=True,  # randomly flip images\n",
    "          rescale=None, # set rescaling factor (applied before any other transformation)\n",
    "          preprocessing_function=None, # set function that will be applied on each input\n",
    "          data_format=None, # image data format, either \"channels_first\" or \"channels_last\"\n",
    "          # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "          validation_split=0.0)\n",
    "\n",
    "      # Compute quantities required for feature-wise normalization\n",
    "      # (std, mean, and principal components if ZCA whitening is applied).\n",
    "      datagen.fit(x_train)\n",
    "\n",
    "      # Fit the model on the batches generated by datagen.flow().\n",
    "      model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                      batch_size=batch_size),epochs=epochs,\n",
    "                          validation_data=(x_test, y_test),\n",
    "                          #class_weight = class_weights,\n",
    "                          callbacks=[csv_logger])\n",
    "    \n",
    "\n",
    "\n",
    "# Warm up training: train the newly added blocks\n",
    "#train_model(epochs=10)\n",
    "#print(\"Releasing all layers...\")\n",
    "# release all layers for training, set all layers trainable and recompile\n",
    "#set_trainable(model)\n",
    "#print(model.summary())\n",
    "\n",
    "# run training\n",
    "train_model(epochs=epochs)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))\n",
    "\n",
    "# Save model\n",
    "# If checkpointer is used, dont use this\n",
    "model.save(weights_path)\n",
    "\n",
    "\n",
    "# Plot and save accuravy loss graphs together\n",
    "def plot_loss_accu_all(history):\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    epochs = range(len(loss))\n",
    "    \n",
    "    plt.plot(epochs, acc, 'r')\n",
    "    plt.plot(epochs, val_acc, 'b')\n",
    "    plt.plot(epochs, loss, 'g')\n",
    "    plt.plot(epochs, val_loss, 'y')\n",
    "    plt.title('Accuracy/Loss')\n",
    "    \n",
    "    #plt.ylabel('Rate')\n",
    "    #plt.xlabel('Epoch')\n",
    "    \n",
    "    plt.legend(['trainacc', 'valacc', 'trainloss', 'valloss'], loc='lower right', fontsize=10)\n",
    "    plt.grid(True)\n",
    "    plt.savefig('{}/{}_acc_loss_graph.jpg'.format(output_path, EXP_NAME), dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "# Plot and save accuravy loss graphs individually\n",
    "def plot_loss_accu(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'g')\n",
    "    plt.plot(epochs, val_loss, 'y')\n",
    "    #plt.title('Training and validation loss')\n",
    "    plt.ylabel('Loss %')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.grid(True)\n",
    "    #plt.savefig('{}/{}_loss.jpg'.format(output_path, EXP_NAME), dpi=100)\n",
    "    plt.savefig('{}/{}_loss.pdf'.format(output_path, EXP_NAME), dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    loss = history.history['acc']\n",
    "    val_loss = history.history['val_acc']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'r')\n",
    "    plt.plot(epochs, val_loss, 'b')\n",
    "    #plt.title('Training and validation accuracy')\n",
    "    plt.ylabel('Accuracy %')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='lower right')\n",
    "    plt.grid(True)\n",
    "    #plt.savefig('{}/{}_acc.jpg'.format(output_path, EXP_NAME), dpi=100)\n",
    "    plt.savefig('{}/{}_acc.pdf'.format(output_path, EXP_NAME), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_accu(model.history)\n",
    "print(\"Done training and logging!\")\n",
    "\n",
    "######################\n",
    "# Define report \n",
    "#report = {}\n",
    "\n",
    "# save metric report\n",
    "#print(report)\n",
    "\n",
    "#with open(\"{}/{}_report.json\".format(output_path, EXP_NAME), 'w') as f:\n",
    "    #for k,v in report.items():\n",
    "        #f.write(str(k))\n",
    "        #f.write(\"--->\")\n",
    "        #f.write(str(v))\n",
    "        \n",
    "        # new line\n",
    "        #f.write(\"\\n\")\n",
    "\n",
    "#f.close()\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csbkPKondraG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train_ISIC_2016.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
